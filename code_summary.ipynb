{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "code_summary.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Main Code"
      ],
      "metadata": {
        "id": "Lrxz_uieUbut"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Install KGE and import all datasets**\n",
        "(included in the cell below aswell but useful for the other tasks)"
      ],
      "metadata": {
        "id": "arTqNty0CUP9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B9cu8WUy2WPN"
      },
      "outputs": [],
      "source": [
        "\n",
        "import os\n",
        "%cd /content/\n",
        "!git clone https://github.com/uma-pi1/kge.git\n",
        "%cd kge\n",
        "!pip install -e .\n",
        "noise=['0','1','2','5','10']\n",
        "datasets=['fb15k-237','fb15k-237_type','wnrr','wnrr_type']\n",
        "for dataset in datasets:\n",
        "  for level in noise:\n",
        "\n",
        "    no_type=dataset.strip('_type')\n",
        "    if \"type\" in dataset:\n",
        "      path=\"/content/drive/MyDrive/experiments/\"+dataset+\"/data/\"+no_type+\"-\"+level+\"nt\"\n",
        "    else:\n",
        "        path=\"/content/drive/MyDrive/experiments/\"+dataset+\"/data/\"+no_type+\"-\"+level+\"n\"\n",
        "    get_ipython().system('cp -r '+path+' /content/kge/data')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Full pipeline for training all models + install KGE and import all datasets**\n",
        "\n",
        "note that this code requires google Colab with a connected Google Drive that contains [this](https://github.com/VR10/kgenoise/tree/master/config%20files/experiments) folder structure. The models can also be individually trained by going into each model folder and starting the training process manually as described in the [LibKGE documentation](https://github.com/uma-pi1/kge) and [here](https://github.com/uma-pi1/kge-iclr20#start-the-hyperparameter-search)\n"
      ],
      "metadata": {
        "id": "Phz0T-PoCHDq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oOcS3JwCez38"
      },
      "outputs": [],
      "source": [
        "\n",
        "import os\n",
        "%cd /content/\n",
        "#install LibKGE\n",
        "!git clone https://github.com/uma-pi1/kge.git\n",
        "%cd kge\n",
        "!pip install -e .\n",
        "#specify models noise levels and datasets that correspond to predfined folder structure\n",
        "modelFolders=[\"rescal-KvsAll-kl-bo-best\",\"rescal-1vsAll-kl-bo-best\",\"transe-negative_sampling-kl-bo-best\",\"distmult-negative_sampling-kl-bo-best\",\"complex-negative_sampling-kl-bo-best\",\"conve-1vsAll-kl-bo-best\",\"complex-1vsAll-kl-bo-best\",\"transe-negative_sampling-kl-bo-best\",\"conve-KvsAll-kl-bo-best\",\"distmult-KvsAll-kl-bo-best\"]\n",
        "noise=['0','1','2','5','10']\n",
        "datasets=['fb15k-237','fb15k-237_type','wnrr','wnrr_type']\n",
        "#copy the datasets from Drive into Colab runtime\n",
        "for dataset in datasets:\n",
        "  for level in noise:\n",
        "    no_type=dataset.strip('_type')\n",
        "    if \"type\" in dataset:\n",
        "      path=\"/content/drive/MyDrive/experiments/\"+dataset+\"/data/\"+no_type+\"-\"+level+\"nt\"\n",
        "    else:\n",
        "        path=\"/content/drive/MyDrive/experiments/\"+dataset+\"/data/\"+no_type+\"-\"+level+\"n\"\n",
        "        print(path)\n",
        "    get_ipython().system('cp -r '+path+' /content/kge/data')\n",
        "os.chdir(\"/content\")   \n",
        "for dataset in datasets:\n",
        "  for level in noise:\n",
        "   for model in modelFolders:   \n",
        "     path=\"/content/drive/MyDrive/experiments/\"+dataset+'/'+level+\"%/\"+model\n",
        "     path_no_model=\"/content/drive/MyDrive/experiments/\"+dataset+'/'+level+\"%/\"\n",
        "     if os.path.exists(path):\n",
        "       print(path)\n",
        "       if os.path.exists(path+'/kge.log'):\n",
        "         #skip folders that contain trained models \n",
        "        with open(path+'/kge.log') as file:\n",
        "         if 'Best result in this training job:' in file.read():\n",
        "          continue\n",
        "       runtime_path=\"/content/\"+dataset+'/'+level+\"%/\"+model\n",
        "       runtime_path_no_model=\"/content/\"+dataset+'/'+level+\"%/\"\n",
        "       os.makedirs(runtime_path, exist_ok=True)\n",
        "       #copy model folder into colab runtime\n",
        "       #Note that training the models dricetly in Drive works but fills up the trash bin in Drive quickly\n",
        "       #Drive also has a cap on the number of daily file access so direct training will fail at some point \n",
        "       get_ipython().system(\"cp -r \"+path+\" \"+runtime_path_no_model)\n",
        "       os.chdir(runtime_path)\n",
        "       #start training\n",
        "       get_ipython().system(\"kge resume . --search.num_workers 4 --search.device_pool cuda:0\")\n",
        "       #copy trained models back to drive since the colab runtime will delete all files once disconnected\n",
        "       get_ipython().system(\"cp -r \"+runtime_path+\" \"+path_no_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Link Prediction for individual triples**"
      ],
      "metadata": {
        "id": "6kloPtZqpns3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#code based on https://github.com/uma-pi1/kge#use-a-pretrained-model-in-an-application\n",
        "import torch\n",
        "from kge.model import KgeModel\n",
        "from kge.util.io import load_checkpoint\n",
        "import sys\n",
        "import numpy as np\n",
        "#to see the full entity ranking\n",
        "np.set_printoptions(threshold=sys.maxsize)\n",
        "#np.set_printoptions(threshold=5)\n",
        "#choose the checkpoint to use\n",
        "checkpoint = load_checkpoint('/content/drive/MyDrive/resulting/fb15k-237_type/0%/complex-negative_sampling-kl-bo-best/checkpoint_best.pt')\n",
        "model = KgeModel.create_from(checkpoint)\n",
        "\n",
        "s = torch.Tensor([0]).long()             # subject indexes\n",
        "p = torch.Tensor([0]).long()             # relation indexes\n",
        "scores = model.score_sp(s, p)                # scores of all objects for (s,p,?)\n",
        "o = torch.argmax(scores, dim=-1)             # index of highest-scoring objects\n",
        "q=torch.argsort(scores, dim=-1)         #get entity ranking\n",
        "print(model.dataset.entity_strings(s))       # convert indexes to mentions\n",
        "print(model.dataset.relation_strings(p))\n",
        "print(model.dataset.entity_strings(o))\n",
        "for index in q:\n",
        " if 0 <= index[1] < len(q):\n",
        "        print(\"Index \",index ,\" in range\")\n",
        "        print(model.dataset.entity_strings(entry))\n",
        " else:\n",
        "        print(\"Index \",index,\" not in range\")\n"
      ],
      "metadata": {
        "id": "Q6yEpPUecH9i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Utilities\n",
        "tasks for csv creation, testing, log file extraction and more"
      ],
      "metadata": {
        "id": "5IrhTHlZUh4a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test all the best models "
      ],
      "metadata": {
        "id": "q7Oghek4CaOQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zsZmes14rOSm"
      },
      "outputs": [],
      "source": [
        "\n",
        "import os\n",
        "import csv\n",
        "import re\n",
        "\n",
        "levels = [0, 1, 2, 5, 10]\n",
        "datasets = [\"fb15k-237\"]\n",
        "modelFolders = [\"rescal-KvsAll-kl-bo-best\", \"rescal-1vsAll-kl-bo-best\", \"transe-negative_sampling-kl-bo-best\",\n",
        "                \"distmult-negative_sampling-kl-bo-best\", \"complex-negative_sampling-kl-bo-best\",\n",
        "                \"conve-1vsAll-kl-bo-best\", \"complex-1vsAll-kl-bo-best\", \"transe-negative_sampling-kl-bo-best\",\n",
        "                \"conve-KvsAll-kl-bo-best\", \"distmult-KvsAll-kl-bo-best\"]\n",
        "for dataset in datasets:\n",
        "    for level in levels:\n",
        "        for model in modelFolders:\n",
        "            #path = \"/content/drive/MyDrive/experiments/\" + dataset + \"/\" + str(level) + \"%/\" + model\n",
        "            path = \"/content/drive/MyDrive/experiments/fb15k-237_noise_training_set_only/\"+ str(level) + \"%/\" + model \n",
        "            if os.path.exists(path):\n",
        "             os.chdir(path)\n",
        "             if os.path.exists('kge.log'):\n",
        "              with open('kge.log') as file1:\n",
        "                  logs=file1.read()\n",
        "                  #get the folder of the best trial from the log file of the search job\n",
        "                  best_folder=re.search(\"Best trial \\([0-9]*\\)\",logs)\n",
        "                  if best_folder != None:\n",
        "                    best_folder=best_folder.group().strip(\"Best trial (\"+')')\n",
        "                    print(best_folder)\n",
        "                    get_ipython().system(\">\"+best_folder+\"_best\")\n",
        "                    path=path+'/'+best_folder\n",
        "                    os.chdir(path)\n",
        "                    #test the best model and dump the results into a txt file\n",
        "                    if not os.path.exists(path+\"/test_dump.txt\"):\n",
        "                      get_ipython().system(\"kge test . > test_dump.txt\")\n",
        "                  "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create CSV with all test results\n"
      ],
      "metadata": {
        "id": "IPzUPv3gCjCa"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZfW87QK3TmRM"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import csv\n",
        "import re\n",
        "\n",
        "levels = [0,1,2,5,10]\n",
        "datasets = [\"fb15k-237\",\"fb15k-237_type\",\"wnrr_type2\",\"wnrr2\",\"wnrr_type\",\"wnrr\"]\n",
        "modelFolders = [\"rescal-KvsAll-kl-bo-best\", \"rescal-1vsAll-kl-bo-best\", \"transe-negative_sampling-kl-bo-best\",\n",
        "                \"distmult-negative_sampling-kl-bo-best\", \"complex-negative_sampling-kl-bo-best\",\n",
        "                \"conve-1vsAll-kl-bo-best\", \"complex-1vsAll-kl-bo-best\",\n",
        "                \"conve-KvsAll-kl-bo-best\", \"distmult-KvsAll-kl-bo-best\"]\n",
        "i=1\n",
        "os.chdir(\"/content/drive/MyDrive/experiments\")\n",
        "with open('tests_final.csv','w') as csvfile:\n",
        " writer= csv.writer(csvfile)\n",
        " writer.writerow([\"dataset\",'noise_level','model','mrr_filtered','mrr','mr_filtered','mr','hits@10_filtered','hits@10','hits@1_filtered','hits@1'])\n",
        " for dataset in datasets:\n",
        "     for level in levels:\n",
        "         for model in modelFolders:\n",
        "           for i in range(5):\n",
        "            path = \"/content/drive/MyDrive/experiments/\" + dataset + \"/\" + str(level) + \"%/\" + model +'/'+ '0000'+str(i)\n",
        "            print(path)\n",
        "            if os.path.exists(path):\n",
        "              os.chdir(path)\n",
        "              if os.path.exists('test_dump.txt'):\n",
        "               with open('test_dump.txt') as file:\n",
        "                   test_dump=file.read()\n",
        "                   #read the test dump, extract all relevant evaluation metrics and print them to a CSV\n",
        "                   mrr=re.search(\"mean_reciprocal_rank: .*\",test_dump).group().strip('mean_reciprocal_rank: ')\n",
        "                   hits10=re.search(\"hits_at_10: .*\",test_dump).group().strip('hits_at_10: ')\n",
        "                   hits10_filtered=re.search(\"hits_at_10_filtered: .*\",test_dump).group().strip('hits_at_10_filtered: ')\n",
        "                   hits1=re.search(\"hits_at_1: .*\",test_dump).group().strip('hits_at_1:')\n",
        "                   hits1_filterd=re.search(\"hits_at_1_filtered: .*\",test_dump).group().strip('hits_at_1_filtered: ')\n",
        "                   mr=re.search(\"mean_rank: .*\",test_dump).group().strip('mean_rank: ')\n",
        "                   mr_filtered=re.search(\"mean_rank_filtered: .*\",test_dump).group().strip('mean_rank_filtered: ')\n",
        "                   mrr_filtered=re.search(\"mean_reciprocal_rank_filtered: .*\",test_dump).group().strip('mean_reciprocal_rank_filtered: ')\n",
        "                   model_name=model.split('-',1)[0]\n",
        "                   line=[dataset,str(level),model_name,mrr_filtered,mrr,mr_filtered,\n",
        "                         mr,hits10_filtered,hits10,hits1_filterd,hits1]\n",
        "                   print(line)\n",
        "                   writer.writerow(line)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create CSV for valid mmr over time"
      ],
      "metadata": {
        "id": "fKFxr6mJCvHI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a-Qs3CFNOU3e"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import csv\n",
        "import re\n",
        "\n",
        "levels = [0,1,2,5,10]\n",
        "datasets = [\"fb15k-237\",\"fb15k-237_type\",\"wnrr_type2\",\"wnrr2\",\"wnrr_type\",\"wnrr\"]\n",
        "modelFolders = [\"rescal-KvsAll-kl-bo-best\", \"rescal-1vsAll-kl-bo-best\", \"transe-negative_sampling-kl-bo-best\",\n",
        "                \"distmult-negative_sampling-kl-bo-best\", \"complex-negative_sampling-kl-bo-best\",\n",
        "                \"conve-1vsAll-kl-bo-best\", \"complex-1vsAll-kl-bo-best\",\n",
        "                \"conve-KvsAll-kl-bo-best\", \"distmult-KvsAll-kl-bo-best\"]\n",
        "\n",
        "epochs=[]\n",
        "os.chdir(\"/content/drive/MyDrive/experiments\")\n",
        "with open('time_progress_val_only.csv','w') as csvfile:\n",
        "  for i in range(401):\n",
        "    if i%5==0 and  i!=0:\n",
        "      epochs.append(i)\n",
        "  writer= csv.writer(csvfile)\n",
        "  header=[\"dataset\",'noise_level','model']\n",
        "  header+=epochs\n",
        "  print(header)\n",
        "  writer.writerow(header)\n",
        "  for dataset in datasets:\n",
        "     for level in levels:\n",
        "         for model in modelFolders:\n",
        "           for i in range(5):\n",
        "            path = \"/content/drive/MyDrive/experiments/\" + dataset + \"/\" + str(level) + \"%/\" + model +'/'+ '0000'+str(i)\n",
        "            print(path)\n",
        "            if os.path.exists(path):\n",
        "              os.chdir(path)\n",
        "              if os.path.exists('test_dump.txt'):\n",
        "               with open('trace.yaml') as trace:\n",
        "                  #trace=file.read()\n",
        "                   print(\"open\")\n",
        "                   i=0\n",
        "                   model_name=model.split('-',1)[0]\n",
        "                   output_line=[dataset,str(level),model_name]\n",
        "                   print(output_line)\n",
        "                   for line in trace:\n",
        "                     if \"eval_completed\" in line:\n",
        "                       print(line)\n",
        "                       output=re.search(\"mean_reciprocal_rank_filtered: .*?(?=,)\",line).group().strip('mean_reciprocal_rank_filtered: ')\n",
        "                       print(output)\n",
        "                       output_line.append(output)\n",
        "                       i+=1\n",
        "                   writer.writerow(output_line)\n",
        " "
      ]
    }
  ]
}